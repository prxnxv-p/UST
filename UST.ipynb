{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prxnxv-p/UST/blob/main/UST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgtsb62ZXTrI",
        "outputId": "f7845482-b3ff-42a1-a991-4971a09e15da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl-kILuPYNap"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from dataclasses import dataclass, field\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCMLUSzwYNdf"
      },
      "outputs": [],
      "source": [
        "\n",
        "@dataclass(eq=True, frozen=True)\n",
        "class TreeNode:\n",
        "    name: str\n",
        "    children: List['TreeNode'] = field(default_factory=list, compare=False, hash=False)\n",
        "    documents: List[str] = field(default_factory=list, compare=False, hash=False)\n",
        "\n",
        "    def add_child(self, child: 'TreeNode') -> None:\n",
        "        self.children.append(child)\n",
        "\n",
        "    def add_document(self, doc: str) -> None:\n",
        "        self.documents.append(doc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcZgMqgUYNg5"
      },
      "outputs": [],
      "source": [
        "class DocumentEncoder:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "\n",
        "    def fit_transform(self, docs: List[str]):\n",
        "        return self.vectorizer.fit_transform(docs).toarray()\n",
        "\n",
        "    def transform(self, doc: str):\n",
        "        return self.vectorizer.transform([doc]).toarray()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYUW-WaPYvR2"
      },
      "outputs": [],
      "source": [
        "class HierarchyTree:\n",
        "    def __init__(self, root_name: str):\n",
        "        self.root = TreeNode(name=root_name)\n",
        "\n",
        "    def add_topic(self, path: List[str]) -> TreeNode:\n",
        "        node = self.root\n",
        "        for name in path:\n",
        "            match = next((child for child in node.children if child.name == name), None)\n",
        "            if not match:\n",
        "                match = TreeNode(name=name)\n",
        "                node.add_child(match)\n",
        "            node = match\n",
        "        return node\n",
        "\n",
        "    def classify_and_assign(self, doc: str, topic_paths: List[List[str]]) -> None:\n",
        "        for path in topic_paths:\n",
        "            node = self.add_topic(path)\n",
        "            node.add_document(doc)\n",
        "\n",
        "    def get_all_documents_under(self, node: TreeNode) -> List[str]:\n",
        "        docs = list(node.documents)\n",
        "        for child in node.children:\n",
        "            docs.extend(self.get_all_documents_under(child))\n",
        "        return docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZFTpcscYvUT"
      },
      "outputs": [],
      "source": [
        "class SearchModule:\n",
        "    def __init__(self, tree: HierarchyTree):\n",
        "        self.tree = tree\n",
        "\n",
        "    def search(self, query: str, top_k: int = 3) -> List[TreeNode]:\n",
        "        candidates = []\n",
        "        node_doc_map = {}\n",
        "\n",
        "        def collect_nodes(node: TreeNode):\n",
        "            if node.documents:\n",
        "                text = ' '.join(node.documents)\n",
        "                node_doc_map[id(node)] = (node, text)\n",
        "                candidates.append(node)\n",
        "            for child in node.children:\n",
        "                collect_nodes(child)\n",
        "\n",
        "        collect_nodes(self.tree.root)\n",
        "\n",
        "        corpus = [val[1] for val in node_doc_map.values()]\n",
        "        if not corpus:\n",
        "            return []\n",
        "\n",
        "        encoder = DocumentEncoder()\n",
        "        corpus_vectors = encoder.fit_transform(corpus)\n",
        "        query_vector = encoder.transform(query)\n",
        "\n",
        "        sims = cosine_similarity(query_vector, corpus_vectors).flatten()\n",
        "        top_indices = sims.argsort()[::-1][:top_k]\n",
        "\n",
        "        return [node_doc_map[list(node_doc_map.keys())[i]][0] for i in top_indices]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toANMxv4YvWu"
      },
      "outputs": [],
      "source": [
        "class RAGModel:\n",
        "    def __init__(self, tree: HierarchyTree):\n",
        "        self.tree = tree\n",
        "        self.searcher = SearchModule(tree)\n",
        "        self.generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "    def query(self, question: str) -> str:\n",
        "        relevant_nodes = self.searcher.search(question)\n",
        "        context_docs = []\n",
        "        for node in relevant_nodes:\n",
        "            context_docs.extend(self.tree.get_all_documents_under(node))\n",
        "\n",
        "        context = \" \".join(context_docs)[:1000]\n",
        "        prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "\n",
        "        result = self.generator(prompt, max_length=150, num_return_sequences=1)[0]['generated_text']\n",
        "        return result.split(\"Answer:\")[-1].strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zYUVOyZYvZL",
        "outputId": "26fb9c07-e03d-41c6-ef1b-db184842210d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# Sample documents\n",
        "documents = [\n",
        "    \"Neural networks and deep learning techniques\",\n",
        "    \"Transformers in NLP applications\",\n",
        "    \"Classical machine learning models like SVM\",\n",
        "    \"Database indexing and SQL queries\",\n",
        "    \"NoSQL systems and distributed databases\"\n",
        "]\n",
        "\n",
        "# Build the tree and classify documents\n",
        "tree = HierarchyTree(\"AI\")\n",
        "tree.classify_and_assign(documents[0], [[\"ML\", \"Deep Learning\"]])\n",
        "tree.classify_and_assign(documents[1], [[\"ML\", \"NLP\"]])\n",
        "tree.classify_and_assign(documents[2], [[\"ML\", \"Classical ML\"]])\n",
        "tree.classify_and_assign(documents[3], [[\"Databases\", \"SQL\"]])\n",
        "tree.classify_and_assign(documents[4], [[\"Databases\", \"NoSQL\"]])\n",
        "\n",
        "#  Create the model\n",
        "rag = RAGModel(tree)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_XZCPD3Yvbm",
        "outputId": "99f8828b-97c4-4106-fa60-e61b0a7dea39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bot: Deep learning techniques are the tools that allow you to learn and learn from a large number of topics.\n",
            "Deep learning is the technology that allows you to use neural networks or machine learning techniques to generate, process, and store information in real-time.\n",
            "Deep learning methods are the tools that allow you to learn and learn from large number of topics.\n",
            "Some deep learning techniques are:\n",
            "SVDT (Simultaneous Neural Networks)\n",
            "SVDT is a new approach to deep learning that allows you to make deep learning decisions using the inputs and outputs of a deep learning model. This model can be used to automatically classify, model, and predict a variety of data sources.\n",
            "This technique uses deep learning data to teach and learn about the social, cultural, and other dimensions of a person's behavior. It does not apply to non-social networks like Facebook, LinkedIn, or Google+.\n",
            "SVDT is a new approach to deep learning that allows you to make deep learning decisions using the inputs and outputs of a deep learning model. This model can be used to automatically classify, model, and predict a variety of data sources. SVDT is a new approach to deep learning that allows you to make deep learning decisions using the inputs and outputs of a deep learning\n"
          ]
        }
      ],
      "source": [
        "#Ask a test question\n",
        "question = \"What are deep learning techniques?\"\n",
        "print(\"\\nBot:\", rag.query(question))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OwzHV5mYwLY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY9endfpYwOy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQFwUlZp/8E4gk4If8eQ+P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}